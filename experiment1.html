<!DOCTYPE html>
<html lang="zh-CN" xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>实验1：RAG检索增强知识问答系统</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="icon" href="media/images/校徽.png">
</head>
<body>
    <!-- 导航栏（苹果风格毛玻璃） -->
    <nav class="nav-bar airglass">
        <div class="nav-content container">
            <a href="index.html" class="logo">
                <img src="media/images/校徽.png" alt="多媒体实验平台logo" class="logo-img">
                多媒体课程实验在线平台</a>
            <ul class="nav-links">
                <li><a href="index.html">返回首页</a></li>
                <li><a href="experiment2.html">实验2</a></li>
                <li><a href="experiment3.html">实验3</a></li>
                <li><a href="experiment4.html">实验4</a></li>
                <li><a href="#content" class="link">实验内容</a></li>
                <li><a href="#steps" class="link">实验步骤</a></li>
                <li><a href="#code" class="link">代码理解</a></li>
            </ul>
        </div>
    </nav>

    <!-- 页头（苹果风格大标题+轻量副标题） -->
    <header class="header">
        <h1>实验 1：RAG检索增强知识问答系统</h1>
        <p>掌握LangChain+FAISS+Qwen构建智能问答系统的核心技术</p>
    </header>

    <!-- 主要内容（苹果风格卡片式布局） -->
    <main class="container">
        <div class="content">
            <!-- 实验内容卡片 -->
            <div class="card">
                <div id="content" class="anchor"></div>
                <h2 class="section-title">一、实验内容</h2>

                <h3 class="sub-title">1. 实验内容</h3>
                <p class="text-content">
                    本实验将使用 RAG（Retrieval-Augmented Generation，检索增强生成）系统进行知识问答实验。RAG 是一种结合了信息检索和生成式 AI 的技术，通过从知识库中检索相关信息来增强大语言模型的回答能力。本实验将学习如何构建一个完整的 RAG 系统，包括文档加载、向量化存储、相似度检索和答案生成等核心模块。
                </p>

                <h3 class="sub-title">2. 实验要点</h3>
                <ul class="custom-list">
                    <li>了解 RAG 系统的基本原理和工作流程</li>
                    <li>学习 LangChain 框架的使用方法</li>
                    <li>掌握文档加载、文本分割、向量化存储等关键技术</li>
                    <li>学会使用 FAISS 进行高效的向量检索</li>
                    <li>理解如何将检索到的上下文信息与大语言模型结合生成答案</li>
                </ul>

                <h3 class="sub-title">3. 实验环境</h3>
                <ul class="custom-list">
                    <li>Python 3</li>
                    <li>LangChain 框架</li>
                    <li>FAISS 向量数据库</li>
                    <li>Qwen 大语言模型（通过 API 端点访问）</li>
                </ul>
            </div>

            <!-- 实验步骤卡片 -->
            <div class="card">
                <div id="steps" class="anchor"></div>
                <h2 class="section-title">二、实验步骤</h2>

                <h3 class="sub-title">1. RAG原理介绍</h3>
                <p class="text-content">
                    RAG（检索增强生成）系统是一种结合了信息检索和生成式 AI 的先进技术。其核心思想是：当用户提出问题时，系统首先从知识库中检索相关的文档片段，然后将这些上下文信息与大语言模型结合，生成更准确、更有依据的答案。
                </p>
                <p class="text-content">
                    本实验构建的检索增强生成（Retrieval-Augmented Generation, RAG）系统基于 LangChain 框架实现，其核心工作流程可概括为三个阶段。首先，在数据入库阶段，将本地文本数据进行预处理与语义分块，并通过嵌入模型生成向量化表示，将其存储于向量数据库中以构建可检索的知识索引。其次，在相关性检索阶段，用户查询同样被编码为向量，并在向量数据库中执行相似度检索；检索结果经过重排序算法筛选，以获取与查询语义最相关的上下文片段。最后，在问题输出阶段，系统将选取的上下文与原始问题共同构建为增强提示（prompt），并输入大语言模型生成回答，从而实现外部知识驱动的高精度问答。整体流程结构清晰、模块化强，便于理解与扩展，能够有效提升模型的知识覆盖与回答可靠性。
                </p>
                <div class="media-container">
                    <img src="media/images/RAG.png" alt="RAG" width="800" height="800">
                </div>

                <h3 class="sub-title">2. 实验步骤1：组装</h3>
                <p class="text-content">当做普通的电脑即可。要连显示屏、鼠标键盘、网线。</p>
                <p class="text-content">桌子上有个小盒子，是英伟达开发板，作为电脑主机。此次实验不使用机械臂。</p>
                <ul class="custom-list">
                    <li>显示屏-HDMI线。可从机械臂上拔下 HDMI 线，一端接开发板，一端接显示屏。</li>
                    <li>显示屏-电源线。一端 USB 口，接开发板的 USB 口；一端 Type-C 口，接显示屏的 Type-C 口（有2个，任意接一个即可）。</li>
                    <li>鼠标键盘。接开发板的 USB 口。</li>
                    <li>网线。接开发板的网口。</li>
                    <li>开发板-电源线。在桌子下面，找直角弯头的那个，一端接桌子腿上的插座，直角弯头接开发板。</li>
                </ul>

                <h3 class="sub-title">3. 实验步骤2：安装依赖</h3>
                <p class="text-content">首先，需要安装项目依赖。在项目根目录下运行：</p>
                <div class="code-block">
pip install -r requirements.txt
                </div>

                <h3 class="sub-title">4. 实验步骤3：构建向量存储</h3>
                <p class="text-content">使用提供的知识库文件 kb.txt 构建向量存储：</p>
                <div class="code-block">
python main.py --mode build --file kb.txt
                </div>
                <p class="text-content">
                    从构建过程可以看出，程序首先成功加载了 kb.txt 并识别为 1 个原始文档，随后在 build_vector_store() 中对文档进行了分割、向量化与索引构建。完成向量化后，FAISS 索引被持久化保存至./vectorstore。整个过程包括文档加载正常、索引构建流程顺利完成、向量存储已被更新并可用于后续查询。
                </p>

                <h3 class="sub-title">5. 实验步骤4：交互式查询</h3>
                <p class="text-content">构建向量存储后，启动交互式查询：</p>
                <div class="code-block">
python main.py --mode interactive
                </div>

                <h3 class="sub-title">6. 实验步骤5：单次查询</h3>
                <p class="text-content">也可以使用单次查询模式：</p>
                <div class="code-block">
python main.py --mode query --question "希冀平台是什么？"
                </div>
                <p class="text-content">
                    实验结果应能看到对于希冀平台的介绍精确且完整，充分体现了RAG在有对应文本内容时，回答问题的准确性、全面性显著提升。
                </p>
                <p class="text-content">
                    接下来可以自己尝试提出相关性强/弱的问题，看看RAG系统的回答，并思考为什么回答结果的准确性会偏差很大。
                </p>

                <h3 class="sub-title">7. 实验步骤5：使用自定义文档</h3>
                <p class="text-content"></p>
                <p class="text-content">使用自己的文档构建知识库，将txt/pdf/文件加载进模型，使用增量添加，生成向量存储并保存。</p>
                <p class="text-content">根据pdf中的内容整合出来了适合问题的信息，内容完善且准确。</p>
            </div>

            <!-- 代码理解卡片 -->
            <div class="card">
                <div id="code" class="anchor"></div>
                <h2 class="section-title">三、代码详解</h2>

                <h3 class="sub-title">1. 项目结构</h3>
                <p class="text-content">本项目的代码采用模块化设计，主要包含以下目录和文件：</p>
                <div class="code-block">
                    <pre><code>
rag_starter/
├── config/              # 配置模块
│   ├── __init__.py
│   └── settings.py      # 配置文件
├── models/              # 模型封装
│   ├── __init__.py
│   ├── llm.py           # LLM 模型封装
│   └── embedding.py     # 嵌入模型封装
├── chains/              # RAG 链
│   ├── __init__.py
│   └── rag_chain.py     # RAG 链实现
├── utils/               # 工具函数
│   ├── __init__.py
│   └── document_loader.py  # 文档加载工具
├── vectorstore/         # 向量存储目录（自动生成）
├── main.py              # 主程序入口
├── requirements.txt     # 依赖文件
├── kb.txt               # 示例知识库文件
└── handbook.md          # 本实验手册
                    </code></pre>
                </div>

                <h3 class="sub-title">2. 配置模块详解</h3>
                <p class="text-content">代码：</p>
                <div class="code-block">
                    <pre><code>
"""
配置文件 - 存储模型端点和其他配置信息
"""
from typing import Optional
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    """应用配置"""

    # LLM 模型配置
    LLM_BASE_URL: str = "http://172.18.144.18/svc/DGsanOif-1/v1"
    LLM_MODEL_NAME: str = "qwen2.5:32b"
    LLM_API_KEY: str = "EMPTY"
    LLM_TEMPERATURE: float = 0.7
    LLM_MAX_TOKENS: int = 2048

    # 嵌入模型配置
    EMBEDDING_BASE_URL: str = "http://172.18.144.18/svc/97iYTIRw-1/v1"
    EMBEDDING_MODEL_NAME: str = "qwen3-embedding:8b"
    EMBEDDING_API_KEY: str = "EMPTY"
    EMBEDDING_DIMENSION: int = 1024  # 根据实际模型调整

    # 向量存储配置
    VECTOR_STORE_PATH: str = "./vectorstore"
    CHUNK_SIZE: int = 1000
    CHUNK_OVERLAP: int = 200

    # 检索配置
    TOP_K: int = 4  # 检索相关文档数量

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# 全局配置实例
settings = Settings()
                    </code></pre>
                </div>
                <p class="text-content">
                    配置模块config.py在本次 RAG 实验中负责完成关键配置，其中包括：LLM 模型配置、嵌入模型配置、向量存储配置以及检索配置。LLM 配置控制最终答案生成的行为，如 API 地址、模型名称、temperature 随机度和最大输出长度，这些参数直接影响生成内容的风格和可靠性。嵌入模型配置定义向量生成服务地址、嵌入模型名称以及向量维度，用于将文本转为语义向量，是检索阶段的核心。向量存储配置则决定文档向量的保存路径与分块策略，CHUNK_SIZE 与 CHUNK_OVERLAP 主要负责调节文本切片的精细度和上下文连续性。检索配置中的 TOP_K 则决定每次返回多少条最相关的向量结果，是影响答案准确度与噪音控制的参数。
                </p>
                <p class="text-content">
                    通过 settings = Settings() 创建全局配置实例，使整个 RAG 系统中任意模块都能一致地访问这些参数。这个配置模块把模型调用、向量生成、数据切片和检索行为统一规范化，为上层的嵌入、检索和生成流程提供了基本的运行环境。
                </p>

                <h3 class="sub-title">3. 模型封装模块详解</h3>
                <p class="text-content">样例代码</p>
                <div class="code-block">
                    <pre><code>
"""
LLM 模型封装 - 使用 LangChain 的 ChatOpenAI 兼容接口
"""
from typing import Optional
from langchain_openai import ChatOpenAI
from langchain_core.language_models.chat_models import BaseChatModel

from config.settings import settings


def get_llm(
    temperature: Optional[float] = None,
    max_tokens: Optional[int] = None,
) -> BaseChatModel:
    """
    获取 LLM 模型实例

    Args:
        temperature: 生成温度，默认使用配置值
        max_tokens: 最大生成token数，默认使用配置值

    Returns:
        LangChain ChatModel 实例
    """
    return ChatOpenAI(
        base_url=settings.LLM_BASE_URL,
        model=settings.LLM_MODEL_NAME,
        temperature=temperature or settings.LLM_TEMPERATURE,
        max_tokens=max_tokens or settings.LLM_MAX_TOKENS,
        api_key=settings.LLM_API_KEY
    )
                    </code></pre>
                </div>
                <p class="text-content">
                    LLM 模型封装模块通过 get_llm() 提供了一个统一且高层的接口，用于获取可直接调用的大语言模型实例。内部基于 LangChain 的 ChatOpenAI 兼容类构建，这使得底层Qwen模型能接入。函数会自动读取配置中的端点、模型名称、温度与最大生成长度，同时允许我们自己通过参数覆盖默认值。返回的模型可直接用于对话、问答或通用文本生成。
                </p>
                <p class="text-content">
                    嵌入模型封装模块则通过 get_embedding_model() 提供了获取文本向量化模型的接口，同样使用 LangChain 的 OpenAIEmbeddings 接口实现标准化封装。其作用是将文本转换为高维向量，用于后续的向量存储、相似度计算与语义检索。该模块完全依赖配置文件读取端点与模型名，从而实现部署环境可替换性。向量化后的结果可用于查询匹配、文档检索或构建向量数据库。
                </p>

                <h3 class="sub-title">4. 工具函数模块详解</h3>
                <p class="text-content">工具函数模块提供了文档加载和文本分割的功能。</p>
                <p class="text-content">样例代码</p>
                <div class="code-block">
                    <pre><code>
"""
文档加载和分割工具
"""
from pathlib import Path
from typing import List, Union

from langchain_community.document_loaders import (
    TextLoader,
    PyPDFLoader,
    UnstructuredMarkdownLoader,
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

from config.settings import settings


def load_documents(file_path: Union[str, Path]) -> List[Document]:
    """
    根据文件类型加载文档

    Args:
        file_path: 文件路径

    Returns:
        文档列表
    """
    file_path = Path(file_path)

    if not file_path.exists():
        raise FileNotFoundError(f"文件不存在: {file_path}")

    suffix = file_path.suffix.lower()

    # 根据文件类型选择加载器
    if suffix == ".txt":
        loader = TextLoader(str(file_path), encoding="utf-8")
    elif suffix == ".pdf":
        loader = PyPDFLoader(str(file_path))
    elif suffix in [".md", ".markdown"]:
        loader = UnstructuredMarkdownLoader(str(file_path))
    else:
        # 默认使用文本加载器
        loader = TextLoader(str(file_path), encoding="utf-8")

    documents = loader.load()
    return documents


def split_documents(documents: List[Document]) -> List[Document]:
    """
    将文档分割成小块

    Args:
        documents: 原始文档列表

    Returns:
        分割后的文档列表
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=settings.CHUNK_SIZE,
        chunk_overlap=settings.CHUNK_OVERLAP,
        length_function=len,
    )

    split_docs = text_splitter.split_documents(documents)
    return split_docs
                        </code></pre>
                </div>
                <p class="text-content">
                    工具函数模块主要是将原始文件加载并切割成适合向量化的语义片段。load_documents() 负责根据不同文件类型自动选择合适的加载器，支持 TXT、PDF 和 Markdown，并统一返回 LangChain 的 Document 对象，使后续步骤能够在结构化的文本数据上处理。文件加载器的封装让系统具备良好的扩展性，未来如果需要支持 Word、HTML 等格式，只需补充对应的加载器即可。同时，它确保文档内容与其元数据完整保留，为检索阶段提供重要信息。
                </p>
                <p class="text-content">
                    split_documents() 则承担文档预处理的核心逻辑，它使用 RecursiveCharacterTextSplitter 按配置中的 CHUNK_SIZE 和 CHUNK_OVERLAP 将文本切分为更小的语义单元。由于向量数据库通常基于片段嵌入，而不是整篇文档嵌入，因此分割是整个 RAG 系统中不可缺少的关键步骤：分得太大影响检索精准度，分得太小则可能丢失语义信息。通过这个模块，RAG 实现具备了对多格式文件的统一加载能力，并能将文本处理成适合向量化、检索与生成的标准化结构。
                </p>

                <h3 class="sub-title">5. RAG 链核心模块详解</h3>
                <p class="text-content">代码略</p>
                <p class="text-content">
                    RAGChain 模块负责整合文档加载、向量构建、检索以及大模型生成四个关键流程。在类的初始化过程中，模块会根据配置自动确定向量存储路径，加载 LLM 模型与嵌入模型，并确保向量存储目录存在。同时将向量存储、检索器与处理链初始化为 None。
                </p>
                <p class="text-content">
                    构建向量存储build_vector_store，文档会首先经过文本分割，变成多个较小且语义一致的片段。随后，这些片段会通过嵌入模型转换成向量，并通过 FAISS 建立高效的相似度检索索引。构建完成后，系统会创建检索器用于后续查询，并将索引持久化保存到本地。
                </p>
                <p class="text-content">
                    加载向量存储load_vector_store则负责启动。在向量库已经构建好的情况下，RAGChain 可以直接从磁盘加载 FAISS 索引，无需重新计算嵌入。加载后，模块会自动重新创建检索器和处理链，以保证系统处于可查询状态。这样，RAG 系统可以随时断点恢复、快速回答问题。
                </p>
                <p class="text-content">
                    在构建 RAG 链_build_chain中，定义了一个明确的提示模板，用于指导 LLM 根据检索到的上下文回答用户问题。然后，它将检索器、格式化函数、Prompt 模板、LLM 和输出解析器以流水线方式串联，形成一个完整的可执行链路。输入问题后，该链会自动检索相关文档、构建提示、生成答案并输出结果。
                </p>
                <p class="text-content">
                    格式化函数_format_docs将多个文档片段整理为适合放入提示模板的结构化上下文。查询函数query则面向用户，执行整条 RAG 链来返回答案。模块还提供 add_documents 方法，用于向现有向量库追加新的知识片段，并自动重建检索器与处理链，实现持续更新知识库的能力。
                </p>

                <h3 class="sub-title">6. 主程序模块详解</h3>
                <p class="text-content">
                    主程序模块提供 build、query 和 interactive 三种模式。程序中argparse 解析用户输入的运行参数，包括运行模式--mode、文档路径--file、查询内容--question、向量存储位置--vector-store，以及是否在构建模式下启用增量追加--append。在 build 模式下，系统会根据指定文件加载文档，然后选择覆盖或追加方式构建向量存储，用于后续检索；在 query 模式下，程序加载已有的向量存储，并执行一次性的问题查询；在 interactive 模式中，系统则进入循环，与用户持续交互，通过实时查询向量库并生成答案，支持退出指令 quit/exit/退出。
                </p>
            </div>

            <!-- 思考题卡片 -->
            <div class="card">
                <h2 class="section-title">四、思考题</h2>

                <h3 class="sub-title">思考题1：RAG 系统相比直接使用大语言模型有什么优势和局限性？</h3>

                <h3 class="sub-title">思考题2：文档分割策略对检索效果有什么影响？</h3>

                <h3 class="sub-title">思考题3：RAG 技术在哪些领域有潜在应用？</h3>

                <div style="text-align: center; margin-top: 40px;">
                    <a href="index.html" class="btn">返回首页</a>
                    <a href="experiment2.html" class="btn btn-outline" style="margin-left: 15px;">进入实验2</a>
                </div>
            </div>

        </div>
    </main>

        <!-- 页脚：3D极光玻璃风格 -->
    <footer class="footer-3d">
        <!-- 1. 背景层：3D网格与INS风光晕（营造空间感） -->
        <div class="footer-decor">
            <div class="blob blob-1"></div>
            <div class="blob blob-2"></div>
            <div class="grid-lines"></div>
        </div>

        <!-- 2. 内容层：悬浮毛玻璃舱 -->
        <div class="container footer-glass airglass">
            <div class="footer-inner">
                <!-- 导航链接 -->
                <div class="footer-links">
                    <a href="index.html">首页</a>
                    <a href="experiment1.html">实验1</a>
                    <a href="experiment2.html">实验2</a>
                    <a href="experiment3.html">实验3</a>
                    <a href="experiment4.html">实验4</a>
                    <a href="https://www.runoob.com/python3/python3-tutorial.html" target="_blank">Python教程</a>
                    <a href="https://python.langchain.com/docs/get_started/introduction" target="_blank">LangChain文档</a>
                </div>

                <!-- 版权信息 -->
                <div class="footer-bottom">
                    <p class="copyright">
                        © 2025 多媒体课程实验在线平台 · 版权所有
                    </p>
                </div>
            </div>
        </div>
    </footer>
</body>
</html>
